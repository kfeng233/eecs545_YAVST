{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_--X5Hmx7T6l"
   },
   "source": [
    "# Prepare the Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip uninstall transformers -y\n",
    "# ! pip install transformers==2.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8875,
     "status": "ok",
     "timestamp": 1712538921042,
     "user": {
      "displayName": "Bill Yan",
      "userId": "12637667030061721530"
     },
     "user_tz": 240
    },
    "id": "cBK60OISktmC",
    "outputId": "4b4705de-f74c-443f-de28-40acc555dc0f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/kaixfeng/.local/lib/python3.10/site-packages (4.39.3)\n",
      "Requirement already satisfied: datasets in /home/kaixfeng/.local/lib/python3.10/site-packages (2.18.0)\n",
      "Requirement already satisfied: requests in /sw/pkgs/arc/python3.10-anaconda/2023.03/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/kaixfeng/.local/lib/python3.10/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /sw/pkgs/arc/python3.10-anaconda/2023.03/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: filelock in /sw/pkgs/arc/python3.10-anaconda/2023.03/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /sw/pkgs/arc/python3.10-anaconda/2023.03/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /sw/pkgs/arc/python3.10-anaconda/2023.03/lib/python3.10/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /sw/pkgs/arc/python3.10-anaconda/2023.03/lib/python3.10/site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/kaixfeng/.local/lib/python3.10/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/kaixfeng/.local/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /sw/pkgs/arc/python3.10-anaconda/2023.03/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/kaixfeng/.local/lib/python3.10/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: aiohttp in /home/kaixfeng/.local/lib/python3.10/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /home/kaixfeng/.local/lib/python3.10/site-packages (from datasets) (15.0.2)\n",
      "Requirement already satisfied: multiprocess in /home/kaixfeng/.local/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/kaixfeng/.local/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /home/kaixfeng/.local/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: pandas in /sw/pkgs/arc/python3.10-anaconda/2023.03/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /home/kaixfeng/.local/lib/python3.10/site-packages (from datasets) (2024.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/kaixfeng/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/kaixfeng/.local/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/kaixfeng/.local/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /sw/pkgs/arc/python3.10-anaconda/2023.03/lib/python3.10/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/kaixfeng/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/kaixfeng/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/kaixfeng/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /sw/pkgs/arc/python3.10-anaconda/2023.03/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /sw/pkgs/arc/python3.10-anaconda/2023.03/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /sw/pkgs/arc/python3.10-anaconda/2023.03/lib/python3.10/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /sw/pkgs/arc/python3.10-anaconda/2023.03/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /sw/pkgs/arc/python3.10-anaconda/2023.03/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /sw/pkgs/arc/python3.10-anaconda/2023.03/lib/python3.10/site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in /sw/pkgs/arc/python3.10-anaconda/2023.03/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Install and import necessary packages\n",
    "! pip install transformers datasets\n",
    "# ! pip install --upgrade transformers\n",
    "# ! pip install transformers datasets av\n",
    "# To install from source instead of the last release, comment the command above and uncomment the following one.\n",
    "# ! pip install git+https://github.com/huggingface/transformers.git\n",
    "\n",
    "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as F\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZQHhfP4_s3pT",
    "tags": []
   },
   "source": [
    "# Define the new X-Clip class with Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 93,
     "status": "ok",
     "timestamp": 1712540305849,
     "user": {
      "displayName": "Bill Yan",
      "userId": "12637667030061721530"
     },
     "user_tz": 240
    },
    "id": "55W4PI-Sszj2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary modules first\n",
    "import torch\n",
    "batch_size = 10\n",
    "\n",
    "class X_Clip_mod(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, device, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "        original_model = torch.load(\"X-CLIP.bin\", map_location = \"cpu\")\n",
    "        \n",
    "        # original_model.load_state_dict(params['state_dict'])\n",
    "        # And move model to GPU\n",
    "        original_model = original_model.to(device)\n",
    "        \n",
    "        self.resnet = torch.load(\"Resnet 101.bin\")\n",
    "        self.preprocessor = DetrImageProcessor.from_json_file(\"preprocessor_config.json\")\n",
    "\n",
    "        # Freeze the Resnet model parameters\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Extract the vision model and make change to its parameters\n",
    "        vision = original_model.base_model.vision_model\n",
    "        vision.embeddings.patch_embedding = torch.nn.Conv2d(2048, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "        vision.embeddings.position_embedding = torch.nn.Embedding(1009, 768)\n",
    "        vision.embeddings.position_ids = torch.arange(1009).expand((1, -1))\n",
    "\n",
    "        # Shrink the vision encoder to 2 layers as they only need to digest the ResNet feautures, not extracting features\n",
    "        # Also, change their number of frames to a typical 10 for processed data.\n",
    "        vision.encoder.layers = vision.encoder.layers[0:2]\n",
    "        for layer in vision.encoder.layers:\n",
    "            layer.num_frames = batch_size\n",
    "\n",
    "        self.vision = vision\n",
    "        del vision\n",
    "\n",
    "        # The visual projection module can be used as is\n",
    "        self.visual_projection = original_model.base_model.visual_projection\n",
    "\n",
    "        # Extract and change the position embedding size of the mit\n",
    "        mit = original_model.base_model.mit\n",
    "        mit.position_embedding = torch.nn.Parameter(torch.rand(1, batch_size, 512))\n",
    "\n",
    "        self.mit = mit\n",
    "        del mit\n",
    "\n",
    "        # And finally the final score prediction layer\n",
    "        self.scoring = torch.nn.Sequential(torch.nn.Linear(512, 1), torch.nn.Sigmoid())\n",
    "\n",
    "    def forward(self, frames) -> torch.Tensor:\n",
    "        '''\n",
    "        Frames shape: (1, num_frames, height, width, RBG_channels)\n",
    "        Output shape: (1, num_frames, 1)\n",
    "        '''\n",
    "        inputs = self.preprocessor(frames.squeeze(dim=0), return_tensors=\"pt\")\n",
    "        \n",
    "        inputs = inputs.to(self.device)\n",
    "        \n",
    "        features, _ = self.resnet(**inputs)\n",
    "        features, _ = features[-1]\n",
    "        \n",
    "        features = features.to(self.device)\n",
    "        \n",
    "        vision_output = self.vision(features)\n",
    "        del features\n",
    "\n",
    "        video_embeds = vision_output[1]\n",
    "        video_embeds = self.visual_projection(video_embeds)\n",
    "\n",
    "        cls_features = video_embeds.view(1, batch_size, -1)\n",
    "\n",
    "        mit_output = self.mit(cls_features)\n",
    "\n",
    "        video_embeds = mit_output[0]\n",
    "\n",
    "        scores = self.scoring(video_embeds)\n",
    "        scores = 4*scores + 1\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gAtAECOCjpci"
   },
   "source": [
    "# Define the dataloader to be used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 112,
     "status": "ok",
     "timestamp": 1712540293234,
     "user": {
      "displayName": "Bill Yan",
      "userId": "12637667030061721530"
     },
     "user_tz": 240
    },
    "id": "lm9NOx2Ztbtx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class X_Clip_Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, device, mode=\"test\") -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        if mode == \"train\":\n",
    "            with open(\"dataset/TVSum/down-sampled frames/train.json\", 'r') as j:\n",
    "                self.frames = json.load(j)\n",
    "        else:\n",
    "            with open(\"dataset/TVSum/down-sampled frames/test.json\", 'r') as j:\n",
    "                self.frames = json.load(j)\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # Read the images\n",
    "        frames_locs = self.frames[i]\n",
    "        # frame_set = torch.stack([F.pil_to_tensor(Image.open(item)).permute(1, 2, 0) for item in frames_locs], dim=0)\n",
    "        frame_set = torch.stack([F.pil_to_tensor(Image.open(item).resize((640, 360))).permute(1, 2, 0) for item in frames_locs], dim=0)\n",
    "\n",
    "        # Read the score tensor\n",
    "        path_items = frames_locs[0].split('/')\n",
    "        target = path_items[-2]\n",
    "        index = int(path_items[-1].rstrip('.jpg'))\n",
    "        score = torch.load(f\"dataset/TVSum/ground truth/{target}.pt\").mean(axis=0)\n",
    "        if index+batch_size > len(score):\n",
    "            score = score[-batch_size:]\n",
    "        else:\n",
    "            score = score[index:index+batch_size]\n",
    "        score = score.reshape((batch_size, 1))\n",
    "        return frame_set, score.float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02a8wxn3rZSd",
    "tags": []
   },
   "source": [
    "# Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 94,
     "status": "ok",
     "timestamp": 1712539117200,
     "user": {
      "displayName": "Bill Yan",
      "userId": "12637667030061721530"
     },
     "user_tz": 240
    },
    "id": "FA9n57uEvuIi",
    "outputId": "cfd509b9-3cae-4c44-b259-35a6a1f49fc7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda\n"
     ]
    }
   ],
   "source": [
    "# Some libraries and model parameters\n",
    "import os\n",
    "\n",
    "checkpoint = 'X_Clip_mod.bin'\n",
    "lr = 0.00001\n",
    "workers = 1\n",
    "iterations = 10000\n",
    "start_epoch = 0\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running on {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 2998,
     "status": "ok",
     "timestamp": 1712540311713,
     "user": {
      "displayName": "Bill Yan",
      "userId": "12637667030061721530"
     },
     "user_tz": 240
    },
    "id": "Nslb8607lr8Z",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    \"\"\"\n",
    "    One epoch's training.\n",
    "\n",
    "    :param train_loader: DataLoader for training data\n",
    "    :param model: model\n",
    "    :param criterion: content loss function (Mean Squared-Error loss)\n",
    "    :param optimizer: optimizer\n",
    "    :param epoch: epoch number\n",
    "    \"\"\"\n",
    "    model.train()  # training mode enables batch normalization\n",
    "    # Batches\n",
    "    for i, (features, scores) in enumerate(train_loader):\n",
    "        print(f'iteration: {i}')\n",
    "        # Move to default device\n",
    "        \n",
    "        features = features.to(device)  # (batch_size=1, 10, 2048, 24, 42)\n",
    "        \n",
    "        scores = scores.to(device)  # (batch_size=1, 10, 1)\n",
    "        # Forward prop.\n",
    "        predict_scores = model(features)  # (batch_size=1, 10, 1)\n",
    "        print(predict_scores, scores)\n",
    "        \n",
    "        # Loss\n",
    "        loss = criterion(predict_scores, scores)  # scalar\n",
    "        \n",
    "        # Backward prop.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update model\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print status\n",
    "        if i % batch_size == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]----'\n",
    "                  'Loss {loss:.4f}'.format(epoch, i, len(train_loader), loss=loss))\n",
    "\n",
    "            # Save checkpoint\n",
    "            torch.save({'epoch': epoch,\n",
    "                        'model': model,\n",
    "                        'optimizer': optimizer},\n",
    "                        'X_Clip_mod.bin')\n",
    "            \n",
    "    del features, scores, predict_scores  # free some memory since their histories may be stored\n",
    "\n",
    "# Initialize model or load checkpoint\n",
    "if not os.path.exists(checkpoint):\n",
    "    model = X_Clip_mod(device)\n",
    "\n",
    "    # Initialize the optimizer\n",
    "    optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "\n",
    "else:\n",
    "    checkpoint = torch.load(checkpoint, map_location=device)\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    model = checkpoint['model']\n",
    "    optimizer = checkpoint['optimizer']\n",
    "\n",
    "# Move to default device\n",
    "model = model.to(device)\n",
    "criterion = torch.nn.MSELoss().to(device)\n",
    "\n",
    "# Custom dataloaders\n",
    "train_dataset = X_Clip_Dataset(device)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=workers, pin_memory=True)  # note that we're passing the collate function here\n",
    "\n",
    "# Total number of epochs to train for\n",
    "epochs = int(iterations // len(train_loader) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 303657,
     "status": "error",
     "timestamp": 1712540616222,
     "user": {
      "displayName": "Bill Yan",
      "userId": "12637667030061721530"
     },
     "user_tz": 240
    },
    "id": "lBT6IlI5277y",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "06833cef-4ebe-41e4-cd43-8efc8d655f1d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0\n",
      "tensor([[[1.8214],\n",
      "         [1.8374],\n",
      "         [1.7793],\n",
      "         [1.7956],\n",
      "         [1.8043],\n",
      "         [1.8997],\n",
      "         [1.8051],\n",
      "         [1.8624],\n",
      "         [1.8891],\n",
      "         [1.8348]]], device='cuda:0', grad_fn=<AddBackward0>) tensor([[[2.],\n",
      "         [2.],\n",
      "         [2.],\n",
      "         [2.],\n",
      "         [2.],\n",
      "         [2.],\n",
      "         [2.],\n",
      "         [2.],\n",
      "         [2.],\n",
      "         [2.]]], device='cuda:0')\n",
      "Epoch: [18][0/2079]----Loss 0.0294\n",
      "iteration: 1\n",
      "tensor([[[1.8167],\n",
      "         [1.8347],\n",
      "         [1.8245],\n",
      "         [1.8288],\n",
      "         [1.7987],\n",
      "         [1.8149],\n",
      "         [1.7727],\n",
      "         [1.8457],\n",
      "         [1.8459],\n",
      "         [1.8493]]], device='cuda:0', grad_fn=<AddBackward0>) tensor([[[1.4000],\n",
      "         [1.4000],\n",
      "         [1.4000],\n",
      "         [1.4000],\n",
      "         [1.4000],\n",
      "         [1.4000],\n",
      "         [1.4000],\n",
      "         [1.4000],\n",
      "         [1.4000],\n",
      "         [1.4000]]], device='cuda:0')\n",
      "iteration: 2\n",
      "tensor([[[2.4201],\n",
      "         [2.4493],\n",
      "         [2.4168],\n",
      "         [2.3433],\n",
      "         [2.3969],\n",
      "         [2.4714],\n",
      "         [2.4783],\n",
      "         [2.4207],\n",
      "         [2.4533],\n",
      "         [2.4936]]], device='cuda:0', grad_fn=<AddBackward0>) tensor([[[2.4500],\n",
      "         [2.4500],\n",
      "         [2.4500],\n",
      "         [2.4500],\n",
      "         [2.4500],\n",
      "         [2.4500],\n",
      "         [2.4500],\n",
      "         [2.4500],\n",
      "         [2.4500],\n",
      "         [2.4500]]], device='cuda:0')\n",
      "iteration: 3\n",
      "tensor([[[2.1745],\n",
      "         [2.2161],\n",
      "         [2.1385],\n",
      "         [2.1987],\n",
      "         [2.1655],\n",
      "         [2.1929],\n",
      "         [2.1577],\n",
      "         [2.1553],\n",
      "         [2.1520],\n",
      "         [2.1939]]], device='cuda:0', grad_fn=<AddBackward0>) tensor([[[2.1500],\n",
      "         [2.1500],\n",
      "         [2.1500],\n",
      "         [2.1500],\n",
      "         [2.1500],\n",
      "         [2.1500],\n",
      "         [2.1500],\n",
      "         [2.1500],\n",
      "         [2.1500],\n",
      "         [2.1500]]], device='cuda:0')\n",
      "iteration: 4\n",
      "tensor([[[2.0251],\n",
      "         [2.0252],\n",
      "         [1.9868],\n",
      "         [1.9652],\n",
      "         [1.9940],\n",
      "         [1.9975],\n",
      "         [2.0495],\n",
      "         [2.0263],\n",
      "         [1.9879],\n",
      "         [1.9926]]], device='cuda:0', grad_fn=<AddBackward0>) tensor([[[1.4000],\n",
      "         [1.4000],\n",
      "         [1.4000],\n",
      "         [1.4000],\n",
      "         [1.4000],\n",
      "         [1.4000],\n",
      "         [1.4000],\n",
      "         [1.4000],\n",
      "         [1.4000],\n",
      "         [1.4000]]], device='cuda:0')\n",
      "iteration: 5\n",
      "tensor([[[1.7577],\n",
      "         [1.7722],\n",
      "         [1.7311],\n",
      "         [1.7201],\n",
      "         [1.7403],\n",
      "         [1.7222],\n",
      "         [1.7261],\n",
      "         [1.7709],\n",
      "         [1.7655],\n",
      "         [1.7515]]], device='cuda:0', grad_fn=<AddBackward0>) tensor([[[1.2500],\n",
      "         [1.2500],\n",
      "         [1.2500],\n",
      "         [1.2500],\n",
      "         [1.2500],\n",
      "         [1.2500],\n",
      "         [1.2500],\n",
      "         [1.2500],\n",
      "         [1.2500],\n",
      "         [1.2500]]], device='cuda:0')\n",
      "iteration: 6\n",
      "tensor([[[2.5956],\n",
      "         [2.5069],\n",
      "         [2.4762],\n",
      "         [2.5735],\n",
      "         [2.5608],\n",
      "         [2.5624],\n",
      "         [2.5450],\n",
      "         [2.6465],\n",
      "         [2.6499],\n",
      "         [2.5422]]], device='cuda:0', grad_fn=<AddBackward0>) tensor([[[2.9500],\n",
      "         [2.9500],\n",
      "         [2.9500],\n",
      "         [2.9500],\n",
      "         [2.9500],\n",
      "         [2.9500],\n",
      "         [2.9500],\n",
      "         [2.9500],\n",
      "         [2.9500],\n",
      "         [2.9500]]], device='cuda:0')\n",
      "iteration: 7\n",
      "tensor([[[1.8967],\n",
      "         [1.9328],\n",
      "         [1.8885],\n",
      "         [1.8671],\n",
      "         [1.8665],\n",
      "         [1.9337],\n",
      "         [1.9134],\n",
      "         [1.9441],\n",
      "         [1.8765],\n",
      "         [1.8959]]], device='cuda:0', grad_fn=<AddBackward0>) tensor([[[1.2500],\n",
      "         [1.2500],\n",
      "         [1.2500],\n",
      "         [1.2500],\n",
      "         [1.2500],\n",
      "         [1.2500],\n",
      "         [1.2500],\n",
      "         [1.2500],\n",
      "         [1.2500],\n",
      "         [1.2500]]], device='cuda:0')\n",
      "iteration: 8\n",
      "tensor([[[2.0928],\n",
      "         [2.0502],\n",
      "         [2.0599],\n",
      "         [2.0723],\n",
      "         [2.0508],\n",
      "         [2.1096],\n",
      "         [2.0442],\n",
      "         [2.0515],\n",
      "         [2.0208],\n",
      "         [2.0570]]], device='cuda:0', grad_fn=<AddBackward0>) tensor([[[1.9000],\n",
      "         [1.9000],\n",
      "         [1.9000],\n",
      "         [1.9000],\n",
      "         [1.9000],\n",
      "         [1.9000],\n",
      "         [1.9000],\n",
      "         [1.9000],\n",
      "         [1.9000],\n",
      "         [1.9000]]], device='cuda:0')\n",
      "iteration: 9\n",
      "tensor([[[2.1912],\n",
      "         [2.2035],\n",
      "         [2.1919],\n",
      "         [2.2146],\n",
      "         [2.1821],\n",
      "         [2.2558],\n",
      "         [2.1822],\n",
      "         [2.2267],\n",
      "         [2.1675],\n",
      "         [2.1611]]], device='cuda:0', grad_fn=<AddBackward0>) tensor([[[2.1000],\n",
      "         [2.1000],\n",
      "         [2.1000],\n",
      "         [2.1000],\n",
      "         [2.1000],\n",
      "         [2.1000],\n",
      "         [2.4000],\n",
      "         [2.4000],\n",
      "         [2.4000],\n",
      "         [2.4000]]], device='cuda:0')\n",
      "iteration: 10\n",
      "tensor([[[1.8940],\n",
      "         [1.9176],\n",
      "         [1.8659],\n",
      "         [1.8832],\n",
      "         [1.8941],\n",
      "         [1.9571],\n",
      "         [1.8910],\n",
      "         [1.9381],\n",
      "         [1.8823],\n",
      "         [1.8942]]], device='cuda:0', grad_fn=<AddBackward0>) tensor([[[1.3500],\n",
      "         [1.3500],\n",
      "         [1.3500],\n",
      "         [1.3500],\n",
      "         [1.3500],\n",
      "         [1.3500],\n",
      "         [1.3500],\n",
      "         [1.3500],\n",
      "         [1.3500],\n",
      "         [1.3500]]], device='cuda:0')\n",
      "Epoch: [18][10/2079]----Loss 0.3051\n",
      "iteration: 11\n",
      "tensor([[[1.9168],\n",
      "         [1.8400],\n",
      "         [1.8642],\n",
      "         [1.8430],\n",
      "         [1.8566],\n",
      "         [1.8333],\n",
      "         [1.8679],\n",
      "         [1.8746],\n",
      "         [1.8738],\n",
      "         [1.8851]]], device='cuda:0', grad_fn=<AddBackward0>) tensor([[[1.6500],\n",
      "         [1.6500],\n",
      "         [1.6500],\n",
      "         [1.6500],\n",
      "         [1.6500],\n",
      "         [1.6500],\n",
      "         [1.6500],\n",
      "         [1.6500],\n",
      "         [1.6500],\n",
      "         [1.6500]]], device='cuda:0')\n",
      "iteration: 12\n",
      "tensor([[[1.8648],\n",
      "         [1.8518],\n",
      "         [1.8772],\n",
      "         [1.9048],\n",
      "         [1.8647],\n",
      "         [1.9016],\n",
      "         [1.8479],\n",
      "         [1.9157],\n",
      "         [1.8687],\n",
      "         [1.9145]]], device='cuda:0', grad_fn=<AddBackward0>) tensor([[[2.],\n",
      "         [2.],\n",
      "         [2.],\n",
      "         [2.],\n",
      "         [2.],\n",
      "         [2.],\n",
      "         [2.],\n",
      "         [2.],\n",
      "         [2.],\n",
      "         [2.]]], device='cuda:0')\n",
      "iteration: 13\n",
      "tensor([[[1.8117],\n",
      "         [1.7798],\n",
      "         [1.8034],\n",
      "         [1.6964],\n",
      "         [1.7510],\n",
      "         [1.7788],\n",
      "         [1.7762],\n",
      "         [1.8311],\n",
      "         [1.7897],\n",
      "         [1.7947]]], device='cuda:0', grad_fn=<AddBackward0>) tensor([[[1.2000],\n",
      "         [1.2000],\n",
      "         [1.2000],\n",
      "         [1.2000],\n",
      "         [1.2000],\n",
      "         [1.2000],\n",
      "         [1.2000],\n",
      "         [1.2000],\n",
      "         [1.2000],\n",
      "         [1.2000]]], device='cuda:0')\n",
      "iteration: 14\n",
      "tensor([[[1.9344],\n",
      "         [1.8646],\n",
      "         [1.9031],\n",
      "         [1.8709],\n",
      "         [1.9015],\n",
      "         [1.7642],\n",
      "         [1.8390],\n",
      "         [1.8568],\n",
      "         [1.8855],\n",
      "         [1.8743]]], device='cuda:0', grad_fn=<AddBackward0>) tensor([[[1.1500],\n",
      "         [1.1500],\n",
      "         [1.1500],\n",
      "         [1.1500],\n",
      "         [1.1500],\n",
      "         [1.1500],\n",
      "         [1.1500],\n",
      "         [1.1500],\n",
      "         [1.1500],\n",
      "         [1.1500]]], device='cuda:0')\n",
      "iteration: 15\n",
      "tensor([[[1.9996],\n",
      "         [1.9410],\n",
      "         [1.9488],\n",
      "         [1.9433],\n",
      "         [1.9971],\n",
      "         [1.9729],\n",
      "         [2.0062],\n",
      "         [1.9777],\n",
      "         [1.9604],\n",
      "         [1.9268]]], device='cuda:0', grad_fn=<AddBackward0>) tensor([[[2.1500],\n",
      "         [2.1500],\n",
      "         [2.1500],\n",
      "         [2.1500],\n",
      "         [2.1500],\n",
      "         [2.1500],\n",
      "         [2.1500],\n",
      "         [2.1500],\n",
      "         [2.1500],\n",
      "         [2.1500]]], device='cuda:0')\n",
      "iteration: 16\n",
      "tensor([[[2.1178],\n",
      "         [2.1142],\n",
      "         [2.1674],\n",
      "         [2.0840],\n",
      "         [2.1192],\n",
      "         [2.0121],\n",
      "         [2.1906],\n",
      "         [2.1600],\n",
      "         [2.1860],\n",
      "         [2.0699]]], device='cuda:0', grad_fn=<AddBackward0>) tensor([[[2.2500],\n",
      "         [2.2500],\n",
      "         [2.2500],\n",
      "         [2.2500],\n",
      "         [2.2500],\n",
      "         [2.2500],\n",
      "         [2.2500],\n",
      "         [2.2500],\n",
      "         [2.2500],\n",
      "         [2.2500]]], device='cuda:0')\n",
      "iteration: 17\n",
      "tensor([[[1.8686],\n",
      "         [1.8084],\n",
      "         [1.8187],\n",
      "         [1.7934],\n",
      "         [1.7807],\n",
      "         [1.7957],\n",
      "         [1.8113],\n",
      "         [1.8433],\n",
      "         [1.8140],\n",
      "         [1.7949]]], device='cuda:0', grad_fn=<AddBackward0>) tensor([[[1.9500],\n",
      "         [1.9500],\n",
      "         [1.9500],\n",
      "         [1.9500],\n",
      "         [1.9500],\n",
      "         [1.9500],\n",
      "         [1.9500],\n",
      "         [1.9500],\n",
      "         [1.9500],\n",
      "         [1.9500]]], device='cuda:0')\n",
      "iteration: 18\n",
      "tensor([[[1.7693],\n",
      "         [1.6915],\n",
      "         [1.6578],\n",
      "         [1.6071],\n",
      "         [1.6868],\n",
      "         [1.6055],\n",
      "         [1.6373],\n",
      "         [1.6915],\n",
      "         [1.7081],\n",
      "         [1.6799]]], device='cuda:0', grad_fn=<AddBackward0>) tensor([[[1.9000],\n",
      "         [1.9000],\n",
      "         [1.9000],\n",
      "         [1.9000],\n",
      "         [1.9000],\n",
      "         [1.9000],\n",
      "         [1.9000],\n",
      "         [1.9000],\n",
      "         [1.9000],\n",
      "         [1.9000]]], device='cuda:0')\n",
      "iteration: 19\n",
      "tensor([[[1.6922],\n",
      "         [1.6632],\n",
      "         [1.6472],\n",
      "         [1.6294],\n",
      "         [1.6550],\n",
      "         [1.5936],\n",
      "         [1.6673],\n",
      "         [1.6980],\n",
      "         [1.6698],\n",
      "         [1.6603]]], device='cuda:0', grad_fn=<AddBackward0>) tensor([[[1.7000],\n",
      "         [1.7000],\n",
      "         [1.7000],\n",
      "         [1.7000],\n",
      "         [1.7000],\n",
      "         [1.7000],\n",
      "         [1.7000],\n",
      "         [1.7000],\n",
      "         [1.7000],\n",
      "         [1.7000]]], device='cuda:0')\n",
      "iteration: 20\n",
      "tensor([[[2.0820],\n",
      "         [2.0173],\n",
      "         [1.9046],\n",
      "         [1.9856],\n",
      "         [1.9903],\n",
      "         [1.9255],\n",
      "         [1.9957],\n",
      "         [2.0310],\n",
      "         [2.0853],\n",
      "         [2.0283]]], device='cuda:0', grad_fn=<AddBackward0>) tensor([[[2.9000],\n",
      "         [2.9000],\n",
      "         [2.9000],\n",
      "         [2.9000],\n",
      "         [2.9000],\n",
      "         [2.9000],\n",
      "         [2.9000],\n",
      "         [2.9000],\n",
      "         [2.9000],\n",
      "         [2.9000]]], device='cuda:0')\n",
      "Epoch: [18][20/2079]----Loss 0.8049\n",
      "iteration: 21\n",
      "tensor([[[1.6749],\n",
      "         [1.6858],\n",
      "         [1.6331],\n",
      "         [1.6518],\n",
      "         [1.6780],\n",
      "         [1.7129],\n",
      "         [1.7084],\n",
      "         [1.7391],\n",
      "         [1.7113],\n",
      "         [1.7041]]], device='cuda:0', grad_fn=<AddBackward0>) tensor([[[1.5000],\n",
      "         [1.5000],\n",
      "         [1.5000],\n",
      "         [1.5000],\n",
      "         [1.5000],\n",
      "         [1.5000],\n",
      "         [1.5000],\n",
      "         [1.5000],\n",
      "         [1.5000],\n",
      "         [1.5000]]], device='cuda:0')\n",
      "iteration: 22\n",
      "tensor([[[1.7769],\n",
      "         [1.6684],\n",
      "         [1.6900],\n",
      "         [1.6617],\n",
      "         [1.6926],\n",
      "         [1.6466],\n",
      "         [1.6980],\n",
      "         [1.7853],\n",
      "         [1.7243],\n",
      "         [1.6898]]], device='cuda:0', grad_fn=<AddBackward0>) tensor([[[1.6000],\n",
      "         [1.6000],\n",
      "         [1.6000],\n",
      "         [1.6000],\n",
      "         [1.6000],\n",
      "         [1.6000],\n",
      "         [1.6000],\n",
      "         [1.6000],\n",
      "         [1.6000],\n",
      "         [1.6000]]], device='cuda:0')\n",
      "iteration: 23\n",
      "tensor([[[1.6532],\n",
      "         [1.6219],\n",
      "         [1.5808],\n",
      "         [1.5776],\n",
      "         [1.5852],\n",
      "         [1.5541],\n",
      "         [1.5444],\n",
      "         [1.5784],\n",
      "         [1.6126],\n",
      "         [1.5751]]], device='cuda:0', grad_fn=<AddBackward0>) tensor([[[1.2500],\n",
      "         [1.2500],\n",
      "         [1.2500],\n",
      "         [1.2500],\n",
      "         [1.2500],\n",
      "         [1.2500],\n",
      "         [1.2500],\n",
      "         [1.2500],\n",
      "         [1.2500],\n",
      "         [1.2500]]], device='cuda:0')\n",
      "iteration: 24\n",
      "tensor([[[2.2556],\n",
      "         [2.3123],\n",
      "         [2.2836],\n",
      "         [2.3378],\n",
      "         [2.2146],\n",
      "         [2.3697],\n",
      "         [2.3420],\n",
      "         [2.3460],\n",
      "         [2.2305],\n",
      "         [2.3517]]], device='cuda:0', grad_fn=<AddBackward0>) tensor([[[2.6000],\n",
      "         [2.6000],\n",
      "         [2.6000],\n",
      "         [2.6000],\n",
      "         [2.6000],\n",
      "         [2.6000],\n",
      "         [2.6000],\n",
      "         [2.6000],\n",
      "         [2.6000],\n",
      "         [2.6000]]], device='cuda:0')\n",
      "iteration: 25\n",
      "tensor([[[2.3342],\n",
      "         [2.2507],\n",
      "         [2.2860],\n",
      "         [2.2480],\n",
      "         [2.2153],\n",
      "         [2.2929],\n",
      "         [2.2663],\n",
      "         [2.3135],\n",
      "         [2.2922],\n",
      "         [2.2646]]], device='cuda:0', grad_fn=<AddBackward0>) tensor([[[2.6000],\n",
      "         [2.6000],\n",
      "         [2.6000],\n",
      "         [2.6000],\n",
      "         [2.6000],\n",
      "         [2.6000],\n",
      "         [2.6000],\n",
      "         [2.6000],\n",
      "         [2.6000],\n",
      "         [2.6000]]], device='cuda:0')\n",
      "iteration: 26\n",
      "tensor([[[1.6097],\n",
      "         [1.5980],\n",
      "         [1.5995],\n",
      "         [1.5636],\n",
      "         [1.5805],\n",
      "         [1.5670],\n",
      "         [1.5782],\n",
      "         [1.5963],\n",
      "         [1.6005],\n",
      "         [1.6103]]], device='cuda:0', grad_fn=<AddBackward0>) tensor([[[1.3500],\n",
      "         [1.3500],\n",
      "         [1.3500],\n",
      "         [1.3500],\n",
      "         [1.3500],\n",
      "         [1.3500],\n",
      "         [1.3500],\n",
      "         [1.3500],\n",
      "         [1.3500],\n",
      "         [1.3500]]], device='cuda:0')\n",
      "iteration: 27\n",
      "tensor([[[1.8124],\n",
      "         [1.7185],\n",
      "         [1.7834],\n",
      "         [1.7236],\n",
      "         [1.7963],\n",
      "         [1.7820],\n",
      "         [1.8138],\n",
      "         [1.7953],\n",
      "         [1.7333],\n",
      "         [1.7755]]], device='cuda:0', grad_fn=<AddBackward0>) tensor([[[1.6000],\n",
      "         [1.6000],\n",
      "         [1.6000],\n",
      "         [1.6000],\n",
      "         [1.6000],\n",
      "         [1.6000],\n",
      "         [1.6000],\n",
      "         [1.6000],\n",
      "         [1.6000],\n",
      "         [1.6000]]], device='cuda:0')\n",
      "iteration: 28\n",
      "tensor([[[1.6924],\n",
      "         [1.6935],\n",
      "         [1.7351],\n",
      "         [1.7237],\n",
      "         [1.7506],\n",
      "         [1.6833],\n",
      "         [1.7453],\n",
      "         [1.7505],\n",
      "         [1.6917],\n",
      "         [1.7700]]], device='cuda:0', grad_fn=<AddBackward0>) tensor([[[1.8500],\n",
      "         [1.8500],\n",
      "         [1.8500],\n",
      "         [1.8500],\n",
      "         [1.8500],\n",
      "         [1.8500],\n",
      "         [1.8500],\n",
      "         [1.8500],\n",
      "         [1.8500],\n",
      "         [1.8500]]], device='cuda:0')\n",
      "iteration: 29\n",
      "tensor([[[1.6287],\n",
      "         [1.5972],\n",
      "         [1.6125],\n",
      "         [1.6212],\n",
      "         [1.5760],\n",
      "         [1.5855],\n",
      "         [1.6017],\n",
      "         [1.6255],\n",
      "         [1.6510],\n",
      "         [1.6124]]], device='cuda:0', grad_fn=<AddBackward0>) tensor([[[1.9500],\n",
      "         [1.9500],\n",
      "         [1.9500],\n",
      "         [1.9500],\n",
      "         [1.9500],\n",
      "         [1.9500],\n",
      "         [1.9500],\n",
      "         [1.9500],\n",
      "         [1.9500],\n",
      "         [1.9500]]], device='cuda:0')\n",
      "iteration: 30\n",
      "tensor([[[1.5729],\n",
      "         [1.5601],\n",
      "         [1.5901],\n",
      "         [1.5627],\n",
      "         [1.5573],\n",
      "         [1.6070],\n",
      "         [1.6035],\n",
      "         [1.6024],\n",
      "         [1.5738],\n",
      "         [1.5650]]], device='cuda:0', grad_fn=<AddBackward0>) tensor([[[1.6500],\n",
      "         [1.6500],\n",
      "         [1.6500],\n",
      "         [1.6500],\n",
      "         [1.6500],\n",
      "         [1.6500],\n",
      "         [1.6500],\n",
      "         [1.6500],\n",
      "         [1.6500],\n",
      "         [1.6500]]], device='cuda:0')\n",
      "Epoch: [18][30/2079]----Loss 0.0053\n",
      "iteration: 31\n",
      "tensor([[[2.5100],\n",
      "         [2.4381],\n",
      "         [2.4677],\n",
      "         [2.4905],\n",
      "         [2.4167],\n",
      "         [2.5167],\n",
      "         [2.4417],\n",
      "         [2.4568],\n",
      "         [2.4359],\n",
      "         [2.4500]]], device='cuda:0', grad_fn=<AddBackward0>) tensor([[[2.6000],\n",
      "         [2.6000],\n",
      "         [2.6000],\n",
      "         [2.6000],\n",
      "         [2.6000],\n",
      "         [2.6000],\n",
      "         [2.6000],\n",
      "         [2.6000],\n",
      "         [2.6000],\n",
      "         [2.6000]]], device='cuda:0')\n",
      "iteration: 32\n",
      "tensor([[[1.9473],\n",
      "         [1.9336],\n",
      "         [1.9319],\n",
      "         [1.9782],\n",
      "         [1.9665],\n",
      "         [1.9390],\n",
      "         [1.9255],\n",
      "         [1.9233],\n",
      "         [1.9540],\n",
      "         [1.9926]]], device='cuda:0', grad_fn=<AddBackward0>) tensor([[[1.7500],\n",
      "         [1.7500],\n",
      "         [1.7500],\n",
      "         [1.7500],\n",
      "         [1.7500],\n",
      "         [1.7500],\n",
      "         [1.7500],\n",
      "         [1.7500],\n",
      "         [1.7500],\n",
      "         [1.7500]]], device='cuda:0')\n",
      "iteration: 33\n",
      "tensor([[[1.8452],\n",
      "         [1.7983],\n",
      "         [1.7990],\n",
      "         [1.7901],\n",
      "         [1.7782],\n",
      "         [1.7434],\n",
      "         [1.7834],\n",
      "         [1.7829],\n",
      "         [1.8563],\n",
      "         [1.7989]]], device='cuda:0', grad_fn=<AddBackward0>) tensor([[[1.2500],\n",
      "         [1.2500],\n",
      "         [1.2500],\n",
      "         [1.2500],\n",
      "         [1.2500],\n",
      "         [1.2500],\n",
      "         [1.2500],\n",
      "         [1.2500],\n",
      "         [1.2500],\n",
      "         [1.2500]]], device='cuda:0')\n",
      "iteration: 34\n",
      "tensor([[[1.4010],\n",
      "         [1.3800],\n",
      "         [1.3912],\n",
      "         [1.3866],\n",
      "         [1.3964],\n",
      "         [1.3828],\n",
      "         [1.3929],\n",
      "         [1.4170],\n",
      "         [1.4211],\n",
      "         [1.3713]]], device='cuda:0', grad_fn=<AddBackward0>) tensor([[[1.2000],\n",
      "         [1.2000],\n",
      "         [1.2000],\n",
      "         [1.2000],\n",
      "         [1.2000],\n",
      "         [1.2000],\n",
      "         [1.2000],\n",
      "         [1.2000],\n",
      "         [1.2000],\n",
      "         [1.2000]]], device='cuda:0')\n",
      "iteration: 35\n",
      "tensor([[[1.6272],\n",
      "         [1.6290],\n",
      "         [1.6374],\n",
      "         [1.5906],\n",
      "         [1.6152],\n",
      "         [1.5636],\n",
      "         [1.6104],\n",
      "         [1.6032],\n",
      "         [1.6340],\n",
      "         [1.5917]]], device='cuda:0', grad_fn=<AddBackward0>) tensor([[[1.4500],\n",
      "         [1.4500],\n",
      "         [1.4500],\n",
      "         [1.4500],\n",
      "         [1.4500],\n",
      "         [1.4500],\n",
      "         [1.4500],\n",
      "         [1.4500],\n",
      "         [1.4500],\n",
      "         [1.4500]]], device='cuda:0')\n",
      "iteration: 36\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_epoch, epochs):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# One epoch's training\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[25], line 21\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, epoch)\u001b[0m\n\u001b[1;32m     19\u001b[0m scores \u001b[38;5;241m=\u001b[39m scores\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# (batch_size=1, 10, 1)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Forward prop.\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m predict_scores \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (batch_size=1, 10, 1)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(predict_scores, scores)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Loss\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 58\u001b[0m, in \u001b[0;36mX_Clip_mod.forward\u001b[0;34m(self, frames)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, frames) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m    Frames shape: (1, num_frames, height, width, RBG_channels)\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m    Output shape: (1, num_frames, 1)\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     62\u001b[0m     features, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresnet(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/image_processing_utils.py:551\u001b[0m, in \u001b[0;36mBaseImageProcessor.__call__\u001b[0;34m(self, images, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, images, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BatchFeature:\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;124;03m\"\"\"Preprocess an image or a batch of images.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/detr/image_processing_detr.py:1388\u001b[0m, in \u001b[0;36mDetrImageProcessor.preprocess\u001b[0;34m(self, images, annotations, return_segmentation_masks, masks_path, do_resize, size, resample, do_rescale, rescale_factor, do_normalize, do_convert_annotations, image_mean, image_std, do_pad, format, return_tensors, data_format, input_data_format, **kwargs)\u001b[0m\n\u001b[1;32m   1385\u001b[0m     images \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrescale(image, rescale_factor, input_data_format\u001b[38;5;241m=\u001b[39minput_data_format) \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images]\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_normalize:\n\u001b[0;32m-> 1388\u001b[0m     images \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   1389\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize(image, image_mean, image_std, input_data_format\u001b[38;5;241m=\u001b[39minput_data_format) \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images\n\u001b[1;32m   1390\u001b[0m     ]\n\u001b[1;32m   1392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_convert_annotations \u001b[38;5;129;01mand\u001b[39;00m annotations \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1393\u001b[0m     annotations \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   1394\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize_annotation(annotation, get_image_size(image, input_data_format))\n\u001b[1;32m   1395\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m annotation, image \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(annotations, images)\n\u001b[1;32m   1396\u001b[0m     ]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/detr/image_processing_detr.py:1389\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1385\u001b[0m     images \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrescale(image, rescale_factor, input_data_format\u001b[38;5;241m=\u001b[39minput_data_format) \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images]\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_normalize:\n\u001b[1;32m   1388\u001b[0m     images \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m-> 1389\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_std\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_data_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_data_format\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images\n\u001b[1;32m   1390\u001b[0m     ]\n\u001b[1;32m   1392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_convert_annotations \u001b[38;5;129;01mand\u001b[39;00m annotations \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1393\u001b[0m     annotations \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   1394\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize_annotation(annotation, get_image_size(image, input_data_format))\n\u001b[1;32m   1395\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m annotation, image \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(annotations, images)\n\u001b[1;32m   1396\u001b[0m     ]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/image_processing_utils.py:621\u001b[0m, in \u001b[0;36mBaseImageProcessor.normalize\u001b[0;34m(self, image, mean, std, data_format, input_data_format, **kwargs)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnormalize\u001b[39m(\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    590\u001b[0m     image: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    596\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;124;03m    Normalize an image. image = (image - image_mean) / image_std.\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;124;03m        `np.ndarray`: The normalized image.\u001b[39;00m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_data_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_data_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/image_transforms.py:403\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(image, mean, std, data_format, input_data_format)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    401\u001b[0m     image \u001b[38;5;241m=\u001b[39m ((image\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m-\u001b[39m mean) \u001b[38;5;241m/\u001b[39m std)\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m--> 403\u001b[0m image \u001b[38;5;241m=\u001b[39m to_channel_dimension_format(image, data_format, input_data_format) \u001b[38;5;28;01mif\u001b[39;00m data_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m image\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    # One epoch's training\n",
    "    train(train_loader=train_loader,\n",
    "            model=model,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            epoch=epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02a8wxn3rZSd",
    "tags": []
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.2644921514249533, tensor(0.5767, device='cuda:0', dtype=torch.float64))\n"
     ]
    }
   ],
   "source": [
    "def evaluate(test_loader, model, criterion, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Evaluate the model.\n",
    "\n",
    "    :param test_loader: DataLoader for test data\n",
    "    :param model: model\n",
    "    :param criterion: loss function\n",
    "    \"\"\"\n",
    "    model.eval()  # evaluation mode disables dropout\n",
    "    total_loss = 0.0\n",
    "    total_corrects = 0\n",
    "\n",
    "    # No need to track gradients for validation, we're not optimizing.\n",
    "    with torch.no_grad():\n",
    "        for i, (features, scores) in enumerate(test_loader):\n",
    "            features = features.to(device)\n",
    "            scores = scores.to(device)\n",
    "\n",
    "            # Forward prop.\n",
    "            predict_scores = model(features)\n",
    "\n",
    "            # Loss\n",
    "            loss = criterion(predict_scores, scores)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy            \n",
    "            binary_predictions = (loss < threshold).float()\n",
    "            total_corrects += (binary_predictions == 1)\n",
    "\n",
    "        avg_loss = total_loss / len(test_loader)\n",
    "        avg_acc = total_corrects.double() / len(test_loader.dataset)\n",
    "\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "test_dataset = X_Clip_Dataset(device)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=True, num_workers=workers, pin_memory=True)\n",
    "print(evaluate(test_loader, model, criterion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcualte F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.635\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def evaluate(model, criterion, data_loader):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for features, scores in data_loader:\n",
    "            features = features.to(device)\n",
    "            scores = scores.to(device)\n",
    "            predict_scores = model(features)\n",
    "            # Round up the scores\n",
    "            predicted_labels = np.round(predict_scores.cpu().numpy())\n",
    "            scores_labels = np.round(scores.cpu().numpy())\n",
    "            # append labels\n",
    "            all_predictions.extend(predicted_labels)\n",
    "            all_targets.extend(scores_labels)\n",
    "            # print(all_predictions)\n",
    "            # print(all_targets)\n",
    "    # convert to 1-d array\n",
    "    all_predictions = np.array(all_predictions).flatten()\n",
    "    all_targets = np.array(all_targets).flatten()\n",
    "    f1 = f1_score(all_targets, all_predictions, average='micro')  # Calculate F1 score\n",
    "    return f1\n",
    "\n",
    "test_dataset = X_Clip_Dataset(device)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=True, num_workers=workers, pin_memory=True)\n",
    "f1_score = evaluate(model, criterion, test_loader)\n",
    "print(\"F1 Score:\", f1_score) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
